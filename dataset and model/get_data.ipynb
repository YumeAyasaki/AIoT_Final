{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nguồn tham khảo:\n",
    "- [Visual Wake word detection - on cAInvas](https://medium.com/ai-techsystems/visual-wake-word-detection-on-cainvas-6ec3424b497e).\n",
    "- [Mainly for training, partly for collect and relabel data](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/person_detection/training_a_model.md).\n",
    "- [Data source](https://www.kaggle.com/datasets/jeffaudi/coco-2014-dataset-for-yolov3?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "ax = json.load(open('coco2014/annotations/instances_val2014.json')) # add link to json file from COCO official website\n",
    "ax = ax['annotations']  # annotations hold category information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  40137\n"
     ]
    }
   ],
   "source": [
    "# Get all picture ids\n",
    "ids = {a['image_id'] for a in ax}\n",
    "\n",
    "print('Number of images: ', len(ids))\n",
    "\n",
    "# We just take a subset of the images\n",
    "# n = 0.01 * len(ids)\n",
    "# ids = np.random.choice(list(ids), int(n), replace=False)\n",
    "# print('New number of images: ', len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clm = ['image_id', 'category_id', 'bbox', 'area', 'iscrowd']\n",
    "\n",
    "rows = []\n",
    "for i in range(len(ax)):\n",
    "    id = ax[i]['image_id']\n",
    "    if id in ids:\n",
    "        iname = str(id).zfill(12)\n",
    "        new_row = {'image_id': iname, 'category_id': ax[i]['category_id'], 'bbox': ax[i]['bbox'], 'area': ax[i]['area'], 'iscrowd': ax[i]['iscrowd']}\n",
    "        rows.append(new_row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=clm)\n",
    "\n",
    "img_names = np.unique(df['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(img_name):\n",
    "    anns = df[df['image_id'] == img_name]\n",
    "    return anns\n",
    "\n",
    "def get_path(img_name):\n",
    "    img_name = 'COCO_val2014_' + img_name + '.jpg'\n",
    "    return os.path.join('coco2014/images/val2014/', img_name)\n",
    "\n",
    "def get_size(img_name):\n",
    "    img = Image.open(get_path(img_name))\n",
    "    width, height = img.size\n",
    "    return width, height\n",
    "\n",
    "def check_human_annotation(img_name, threshold=0.005):\n",
    "    '''\n",
    "    Check if the image has human annotation. Human's area is larger than threshold.\n",
    "    If there is a human:\n",
    "        - If the human is in the left third of the image, return True, 'left'\n",
    "        - If the human is in the right third of the image, return True, 'right'\n",
    "        - If the human cannot be categorized as left or right, return True, 'none'\n",
    "    If there is no human, return False, 'none'\n",
    "    '''\n",
    "    anns = get_annotations(img_name)\n",
    "    width, height = get_size(img_name)\n",
    "    human_anns = anns[(anns['category_id'] == 1) & (anns['area'] > threshold * width * height)]\n",
    "    if len(human_anns) == 0:\n",
    "        return False, 'none'\n",
    "\n",
    "    main_human = human_anns['area'].argmax()\n",
    "\n",
    "    if len(human_anns) > 1 and human_anns['area'].values[main_human] < 0.7 * human_anns['area'].sum():\n",
    "        return True, 'none'\n",
    "\n",
    "    bbox = human_anns['bbox'].values[0]\n",
    "    left_x, right_x = bbox[0], bbox[0] + bbox[2]\n",
    "\n",
    "    if right_x < 0.33 * width:\n",
    "        return True, 'left'\n",
    "    elif left_x > 0.66 * width:\n",
    "        return True, 'right'\n",
    "    else:\n",
    "        return True, 'none'\n",
    "        \n",
    "# Test\n",
    "def test(img_name):\n",
    "    result = check_human_annotation(img_name)\n",
    "    # Visualize the image\n",
    "    # Also, if there is a human, visualize the bounding box\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    def show_image(img_name):\n",
    "        img = Image.open(get_path(img_name))\n",
    "        if result[0]:\n",
    "            anns = get_annotations(img_name)\n",
    "            human_anns = anns[anns['category_id'] == 1]\n",
    "            width, height = get_size(img_name)\n",
    "            threshold = 0.005\n",
    "            human_anns = human_anns[human_anns['area'] > threshold * width * height]\n",
    "            # Biggest human\n",
    "            main_human = human_anns['area'].argmax()\n",
    "            for human in range(len(human_anns)):\n",
    "                bbox = human_anns['bbox'].values[human]\n",
    "                print(bbox)\n",
    "                left_x = bbox[0]\n",
    "                right_x = bbox[0] + bbox[2]\n",
    "                top_y = bbox[1]\n",
    "                bottom_y = bbox[1] + bbox[3]\n",
    "                if human == main_human:\n",
    "                    plt.plot([left_x, right_x], [top_y, top_y], color='g')\n",
    "                    plt.plot([left_x, right_x], [bottom_y, bottom_y], color='g')\n",
    "                    plt.plot([left_x, left_x], [top_y, bottom_y], color='g')\n",
    "                    plt.plot([right_x, right_x], [top_y, bottom_y], color='g')\n",
    "                else:\n",
    "                    plt.plot([left_x, right_x], [top_y, top_y], color='r')\n",
    "                    plt.plot([left_x, right_x], [bottom_y, bottom_y], color='r')\n",
    "                    plt.plot([left_x, left_x], [top_y, bottom_y], color='r')\n",
    "                    plt.plot([right_x, right_x], [top_y, bottom_y], color='r')\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "    show_image(img_name)\n",
    "\n",
    "# test('000000000113')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images with person on the left:  852\n",
      "Number of images with person on the right:  856\n",
      "Number of images with person but cannot determine left or right:  17399\n",
      "Number of images with no person:  21030\n"
     ]
    }
   ],
   "source": [
    "# We will separate the images into 4 groups: Have person on the left, right, just have person (but can't determine left or right), and no person\n",
    "left = []\n",
    "right = []\n",
    "no = []\n",
    "both = [] # Or neither\n",
    "\n",
    "for i in range(len(img_names)):\n",
    "    img = img_names[i]\n",
    "    img_path = get_path(img)\n",
    "\n",
    "    # Check if image exists\n",
    "    if os.path.isfile(img_path):\n",
    "        # Check if image has person\n",
    "        has_human, side = check_human_annotation(img)\n",
    "        if has_human:\n",
    "            if side == 'left':\n",
    "                left.append(img)\n",
    "            elif side == 'right':\n",
    "                right.append(img)\n",
    "            else:\n",
    "                both.append(img)\n",
    "        else:\n",
    "            no.append(img)\n",
    "\n",
    "print('Number of images with person on the left: ', len(left))\n",
    "print('Number of images with person on the right: ', len(right))\n",
    "print('Number of images with person but cannot determine left or right: ', len(both))\n",
    "print('Number of images with no person: ', len(no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder for the new dataset\n",
    "os.mkdir('vwwd')\n",
    "os.mkdir('vwwd/left')\n",
    "os.mkdir('vwwd/right')\n",
    "os.mkdir('vwwd/both')\n",
    "os.mkdir('vwwd/no')\n",
    "\n",
    "# Copy images to the new folder\n",
    "import shutil\n",
    "for img in left:\n",
    "    shutil.copy(get_path(img), 'vwwd/left')\n",
    "\n",
    "for img in right:\n",
    "    shutil.copy(get_path(img), 'vwwd/right')\n",
    "\n",
    "for img in both:\n",
    "    shutil.copy(get_path(img), 'vwwd/both')\n",
    "\n",
    "for img in no:\n",
    "    shutil.copy(get_path(img), 'vwwd/no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1000 files from the both and no folders\n",
    "import random\n",
    "\n",
    "def select_1k(folder):\n",
    "    os.mkdir(folder + '_1k')\n",
    "    files = os.listdir(folder)\n",
    "    random.shuffle(files)\n",
    "    files = files[:1000]\n",
    "    for file in files:\n",
    "        shutil.move(os.path.join(folder, file), os.path.join(folder + '_1k', file))\n",
    "\n",
    "select_1k('vwwd/both')\n",
    "select_1k('vwwd/no')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
